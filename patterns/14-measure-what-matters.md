# Pattern: Meaningful Measurement

## Context

Your organization wants to improve delivery performance but relies on anecdotal feedback or vanity metrics like “number of features shipped.” Teams lack objective data to guide improvement, and leadership struggles to identify bottlenecks or validate progress.

## Problem

Without meaningful metrics, improvement efforts are blind. Decisions are based on assumptions, not evidence. Teams optimize for output rather than flow or stability, leading to burnout and poor customer experience.

## Forces

* Stakeholders want proof of progress and ROI.
* Teams need actionable insights, not arbitrary targets.
* Traditional metrics (e.g., velocity, story points) do not correlate with business outcomes.
* Fear of measurement being used punitively undermines trust.

## Solution

Adopt the **DORA 4 Key Metrics**—Deployment Frequency, Lead Time for Changes, Change Failure Rate, and Mean Time to Recovery—as the foundation for empirical governance. These metrics provide a balanced view of speed and stability. Use them to:

* Track engineering health and delivery flow.
* Guide coaching and improvement experiments.
* Correlate technical practices (e.g., CI/CD, trunk-based development) with business outcomes. Review trends regularly, focusing on learning and improvement—not punishment.

## Result

Teams gain clarity on what drives performance. Leadership makes evidence-based decisions. Delivery becomes faster and safer, with resilience built into the system. Improvement efforts are targeted and measurable, fostering trust and transparency.

## Related Patterns

* Continuous Delivery
* Flow First
* Collaborative Improvement
* Work Visualisation
