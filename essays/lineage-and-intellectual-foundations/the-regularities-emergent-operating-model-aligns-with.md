# The Regularities Emergent Operating Model Aligns With

Emergent Operating Model (EOM) did not begin as a theoretical exercise.

It emerged from repeated observation:\
the same patterns of behaviour, failure, and recovery appearing across different organisations, domains, and change efforts.

It is clear that these are not isolated problems or poor implementations.\
They reflect **stable regularities in how socio-technical systems behave under uncertainty**.

EOM does not attempt to formalise these regularities as theory.\
It does something more practical: **it designs an operating model that does not fight them**.

This essay surfaces a small set of well-established principles that EOM consistently aligns with—often implicitly—and explains how they are reflected in the model.

***

### Behaviour Follows Measurement

A recurring failure mode in organisations is the corruption of good intent by measurement.

When indicators become targets, behaviour adapts to satisfy the indicator rather than the underlying purpose. This dynamic is widely known as _Goodhart’s Law_, attributed to Charles Goodhart.

EOM absorbs this principle directly:

* metrics are treated as **signals**, not objectives
* trends matter more than point values
* measures are used to provoke inquiry, not to reward or punish

This is why EOM consistently resists metric-driven performance management.\
It recognises that once numbers are used for control, learning collapses.

The regularity is simple:\
**people optimise for what is measured when it affects their safety, status, or funding**.

***

### Structure Shapes Outcomes

Another well-known observation is _Conway’s Law_, associated with Melvin Conway:

> systems tend to reflect the communication structures of the organisations that build them

EOM generalises this beyond software.

Team structures, value streams, funding boundaries, and governance forums all imprint themselves onto outcomes. This is why EOM treats organisational design as a **system effect**, not a first-order decision.

Rather than prescribing team shapes, EOM focuses on:

* constraints that influence coordination cost
* flow signals that reveal structural friction
* coherence through shared intent, not uniform structure

Teams form the way the system makes easiest.

***

### Prediction Breaks Down Under Uncertainty

In complex product environments, planning accuracy degrades rapidly.

This is not due to incompetence or poor discipline. It is a consequence of the _planning fallacy_ and the nature of uncertainty itself.

EOM reflects this by:

* framing strategy and investment as hypotheses
* distinguishing aspirational outcomes from high-integrity commitments
* staging commitment to match learning

The regularity EOM accepts is uncomfortable but consistent:

> **certainty demanded before learning produces confidence theatre, not control**

This is why EOM treats early certainty as a systemic risk, not a virtue.

***

### Flow Reveals System Health

Queueing theory and operational research have long shown that work in progress dominates lead time. As utilisation increases, flow degrades non-linearly.

EOM internalises this without formal theory by:

* optimising for flow over utilisation
* treating WIP as a governance concern
* using time-to-learning as a primary signal

Flow is not a delivery optimisation goal in EOM.\
It is a **diagnostic lens** that reveals hidden system constraints.

***

### Local Optimisation Harms Global Outcomes

One of the most persistent regularities in systems is this:

> behaviour that is rational locally can still degrade the whole

Teams protecting themselves from risk, uncertainty, or blame often act entirely sensibly. Yet collectively, those actions can slow learning, extend lead times, and increase systemic fragility.

EOM does not attempt to eliminate local optimisation through enforcement.\
It treats it as **diagnostic evidence** that constraints are misaligned.

This is why EOM focuses so heavily on system-level design rather than behavioural correction.

***

### Learning Collapses When Being Wrong Is Costly

Research in high-reliability systems and organisational psychology shows a consistent pattern:

when the cost of being wrong is high, people stop exploring and start defending.

EOM reflects this through:

* incremental and reversible commitments
* adaptive funding tied to learning
* governance framed as sensing rather than approval
* explicit protection for hypothesis invalidation

Psychological safety is not mandated in EOM.\
It **emerges when the system makes learning survivable**.

***

### The Synthesis: One Governing Insight

All of these regularities converge into a single anchor that EOM makes explicit:

> **People behave rationally within the constraints of the operating model they inhabit.**

This is not a moral claim.\
It is an operational one.

EOM does not attempt to fight these regularities.\
It uses them.

***

### Why This Matters

Many operating models fail because they are built in opposition to these dynamics:

* they expect metrics to motivate without distortion
* they expect structure to change behaviour by mandate
* they expect certainty to precede learning
* they expect people to act against their own perceived risk

EOM exists because those expectations rarely hold.

By aligning with these regularities instead, EOM allows:

* learning to guide behaviour
* flow to expose real constraints
* governance to evolve decisions
* adaptation to persist without enforcement

***

### In Summary

Emergent Operating Model is not grounded in theory for its own sake.

It is grounded in **what reliably happens** when organisations operate under uncertainty.

These principles do not make EOM true.\
They explain why it is _plausible_.

EOM’s contribution is not new ideas, but coherence:\
an operating model that stops asking people to fight the system—and starts redesigning the system so learning becomes the rational choice.
